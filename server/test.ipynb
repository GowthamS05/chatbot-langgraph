{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated, Optional, Dict, Any, List, Union\n",
    "from langgraph.graph import add_messages, StateGraph, END\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from uuid import uuid4\n",
    "import json\n",
    "import pandas as pd\n",
    "import asyncio\n",
    "from langchain_core.messages import AIMessage, HumanMessage, ToolMessage, SystemMessage\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field \n",
    "from typing import Annotated, Sequence, List, Literal \n",
    "from langgraph.types import Command \n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize LLM\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.0)\n",
    "search_tool = TavilySearchResults(max_results=1)\n",
    "tools = [search_tool]\n",
    "llm_with_tools = model.bind_tools(tools)\n",
    "\n",
    "# Set up memory and tools\n",
    "memory = MemorySaver()\n",
    "\n",
    "# Create a mock JSON dataset for demonstration\n",
    "MOCK_JSON = \"\"\"\n",
    "[\n",
    "    {\"date\": \"2023-01-01\", \"sales\": 1200, \"region\": \"North\", \"product\": \"Widget A\"},\n",
    "    {\"date\": \"2023-01-01\", \"sales\": 950, \"region\": \"South\", \"product\": \"Widget A\"},\n",
    "    {\"date\": \"2023-01-01\", \"sales\": 1500, \"region\": \"East\", \"product\": \"Widget B\"},\n",
    "    {\"date\": \"2023-01-01\", \"sales\": 1100, \"region\": \"West\", \"product\": \"Widget B\"},\n",
    "    {\"date\": \"2023-01-02\", \"sales\": 1300, \"region\": \"North\", \"product\": \"Widget A\"},\n",
    "    {\"date\": \"2023-01-02\", \"sales\": 1000, \"region\": \"South\", \"product\": \"Widget A\"},\n",
    "    {\"date\": \"2023-01-02\", \"sales\": 1600, \"region\": \"East\", \"product\": \"Widget B\"},\n",
    "    {\"date\": \"2023-01-02\", \"sales\": 1050, \"region\": \"West\", \"product\": \"Widget B\"}\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "# Define the state type\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    request_type: str\n",
    "    formula: Optional[str]\n",
    "    dataframe: Optional[Dict[str, Any]]\n",
    "\n",
    "# Supervisor model definition\n",
    "class Supervisor(BaseModel):\n",
    "    next: Literal[\"summary\", \"open_prompt\", \"model\"] = Field(\n",
    "        description=\"Determines which specialist to activate next in the workflow sequence: \"\n",
    "                    \"'summary' When user ask question regarding summary of the table. \"\n",
    "                    \"'open_prompt' When he asks question about data table. Eg) What is my highest or lowest \"\n",
    "                    \"'model' When user ask about current happening or some thing that can be searched in google \"\n",
    "    )\n",
    "    reason: str = Field(\n",
    "        description=\"Detailed justification for the routing decision, explaining the rationale behind selecting the particular specialist and how this advances the task toward completion.\"\n",
    "    )\n",
    "\n",
    "# Node definitions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def supervisor(state: State) -> Command:\n",
    "    system_prompt = '''\n",
    "Act like a supervisor agent in a multi-agent system. Your job is to decide which specialist to activate based on the user's question.\n",
    "\n",
    "Return only one of the following strings:\n",
    "- \"summary\" → when the user asks for a summary of a table.\n",
    "- \"open_prompt\" → when the user asks specific questions about data, e.g., highest or lowest values.\n",
    "- \"model\" → when the user asks about current events or things you'd find on Google.\n",
    "\n",
    "Only return one of the four strings. Do not explain. Do not respond to the user.\n",
    "\n",
    "Take a deep breath and work on this problem step-by-step.\n",
    "'''\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},  \n",
    "    ] + state[\"messages\"] \n",
    "\n",
    "    response = model.with_structured_output(Supervisor).invoke(messages)\n",
    "\n",
    "    goto = response.next\n",
    "    reason = response.reason\n",
    "    \n",
    "    return Command(    \n",
    "        update={\n",
    "            \"request_type\": goto,\n",
    "            \"messages\": [\n",
    "                HumanMessage(content=reason, name=\"supervisor\")\n",
    "            ]\n",
    "        },\n",
    "        goto=goto,  \n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def open_prompt(state: State) -> Dict:\n",
    "    \"\"\"\n",
    "    Converts user query to a pandas DataFrame formula.\n",
    "    \"\"\"\n",
    "    # Get the last human message\n",
    "    human_messages = [msg for msg in state[\"messages\"] if isinstance(msg, HumanMessage)]\n",
    "    last_human_message = human_messages[-1].content\n",
    "    \n",
    "    # Create a prompt for the LLM to generate a pandas formula\n",
    "    prompt = f\"\"\"\n",
    "    Convert the following user query into a pandas DataFrame formula.\n",
    "    Use 'df' as the variable name for the DataFrame.\n",
    "    \n",
    "    User query: {last_human_message}\n",
    "    \n",
    "    Example:\n",
    "    If the query is \"Find sales above 1200 in the East region\", the formula would be:\n",
    "    df[(df['sales'] > 1200) & (df['region'] == 'East')]\n",
    "    \n",
    "    Only return the pandas code, nothing else.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Generate formula using LLM\n",
    "    formula_result = await model.ainvoke([HumanMessage(content=prompt)])\n",
    "    formula = formula_result.content.strip()\n",
    "    \n",
    "    # Clean up the formula (remove backticks if present)\n",
    "    if formula.startswith(\"```python\"):\n",
    "        formula = formula.split(\"```python\")[1]\n",
    "    if formula.endswith(\"```\"):\n",
    "        formula = formula.split(\"```\")[0]\n",
    "    formula = formula.strip()\n",
    "    \n",
    "    # Update state with the formula\n",
    "    return {\n",
    "        \"formula\": formula,\n",
    "        \"messages\": state[\"messages\"]  # Keep existing messages\n",
    "    }\n",
    "\n",
    "async def open_prompt_validator(state: State) -> Union[Dict, str]:\n",
    "    \"\"\"\n",
    "    Validates the formula by running it against the DataFrame.\n",
    "    Uses the REPL tool to execute the formula and check the results.\n",
    "    \"\"\"\n",
    "    # Get the formula from state\n",
    "    formula = state.get(\"formula\")\n",
    "    if not formula:\n",
    "        return {\"messages\": [AIMessage(content=\"No formula found to validate.\")]}\n",
    "    \n",
    "    \n",
    "\n",
    "    # This would normally use the actual REPL tool, but here we'll simulate it\n",
    "    try:\n",
    "        # In a real implementation, you would use something like:\n",
    "        # repl_result = await repl_tool.ainvoke({\"code\": code})\n",
    "        \n",
    "        # For demonstration, let's simulate REPL execution\n",
    "        # Parse mock JSON data\n",
    "        data = json.loads(MOCK_JSON)\n",
    "        df = pd.DataFrame(data)\n",
    "        \n",
    "        # Safely evaluate the formula (note: this is simplified for demo)\n",
    "        # In production, use a proper REPL or sanitized eval\n",
    "        local_vars = {\"df\": df}\n",
    "        try:\n",
    "            # Very unsafe in production, use proper repl tool instead\n",
    "            result_df = eval(formula, {\"__builtins__\": {}}, local_vars)\n",
    "            if not isinstance(result_df, pd.DataFrame):\n",
    "                if isinstance(result_df, pd.Series):\n",
    "                    result_df = result_df.to_frame()\n",
    "                else:\n",
    "                    result_df = pd.DataFrame()\n",
    "            \n",
    "            row_count = len(result_df)\n",
    "            \n",
    "            if row_count > 0:\n",
    "                result_preview = result_df.head(10).to_dict(orient='records')\n",
    "                result_message = f\"Preview: {json.dumps(result_preview, indent=2)}\"\n",
    "                prompt = f\"\"\"\n",
    "                    Act as a data expert analyst ,\n",
    "                    Please summarize the following data :\n",
    "                    {result_message}\n",
    "                    Provide key insights about the data.Make sure its consice.\n",
    "                    \"\"\"\n",
    "        \n",
    "                summary_result = await model.ainvoke([HumanMessage(content=prompt)])\n",
    "                return {\n",
    "                    \"messages\": [AIMessage(content=summary_result.content)],\n",
    "                    \"request_type\": \"open_prompt\"\n",
    "\n",
    "                }\n",
    "          \n",
    "            else:\n",
    "                # No rows found, go back to formula node\n",
    "                return {\n",
    "                    \"messages\": [AIMessage(content=\"Please try again!!!!\")],\n",
    "                    \"request_type\": \"open_prompt\"\n",
    "\n",
    "                }\n",
    "                \n",
    "        except Exception as e:\n",
    "            # Formula error, go back to formula node\n",
    "            error_message = f\"Error in formula: {str(e)}. Let me try a different approach.\"\n",
    "            return {\n",
    "                \"messages\": [AIMessage(content=error_message)],\n",
    "                \"formula\": None  # Clear the invalid formula\n",
    "            }\n",
    "            \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"messages\": [AIMessage(content=f\"Validation error: {str(e)}\")],\n",
    "            \"formula\": None  # Clear the formula on error\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def summary(state: State) -> Dict:\n",
    "    \"\"\"\n",
    "    Converts mock JSON to DataFrame, calculates summary statistics,\n",
    "    and updates the state with this information.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        data = json.loads(MOCK_JSON)\n",
    "        df = pd.DataFrame(data)\n",
    "        \n",
    "        # Calculate summary statistics for numeric columns\n",
    "        numeric_cols = df.select_dtypes(include=['number']).columns\n",
    "        summary_data = {}\n",
    "        \n",
    "        for col in numeric_cols:\n",
    "            summary_data[col] = {\n",
    "                \"min\": df[col].min(),\n",
    "                \"max\": df[col].max(),\n",
    "                \"avg\": df[col].mean()\n",
    "            }\n",
    "        \n",
    "        # Prepare data for LLM summarization\n",
    "        prompt = f\"\"\"\n",
    "        Please summarize the following data statistics:\n",
    "        {summary_data}\n",
    "        Provide key insights about the data . Make sure its consice.\n",
    "        \"\"\"\n",
    "        \n",
    "        summary_result = await model.ainvoke([HumanMessage(content=prompt)])\n",
    "        \n",
    "        # Return updated state with summary data\n",
    "        return {\n",
    "            \"messages\": [AIMessage(content=summary_result.content)],\n",
    "            \"request_type\": \"summary_chat\"\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        error_msg = f\"Error in summary node: {str(e)}\"\n",
    "        return {\"messages\": [AIMessage(content=error_msg)]}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def model_node(state: State) -> Dict:\n",
    "    \"\"\"LLM node that processes messages.\"\"\"\n",
    "    result = await llm_with_tools.ainvoke(state[\"messages\"])\n",
    "    return {\n",
    "        \"messages\": [result],\n",
    "        \"request_type\": \"model_response\"\n",
    "    }\n",
    "\n",
    "async def tools_router(state: State) -> str:\n",
    "    \"\"\"Routes to tool_node if the last message has tool calls, otherwise ends.\"\"\"\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if hasattr(last_message, \"tool_calls\") and len(last_message.tool_calls) > 0:\n",
    "        return \"tool_node\"\n",
    "    else: \n",
    "        return END\n",
    "\n",
    "async def tool_node(state: State) -> Dict:\n",
    "    \"\"\"Custom tool node that handles tool calls from the LLM.\"\"\"\n",
    "    # Get the tool calls from the last message\n",
    "    tool_calls = state[\"messages\"][-1].tool_calls\n",
    "    \n",
    "    # Initialize list to store tool messages\n",
    "    tool_messages = []\n",
    "    \n",
    "    # Process each tool call\n",
    "    for tool_call in tool_calls:\n",
    "        tool_name = tool_call[\"name\"]\n",
    "        tool_args = tool_call[\"args\"]\n",
    "        tool_id = tool_call[\"id\"]\n",
    "        \n",
    "        # Handle the search tool\n",
    "        if tool_name == \"tavily_search_results_json\":\n",
    "            # Execute the search tool with the provided arguments\n",
    "            search_results = await search_tool.ainvoke(tool_args)\n",
    "            \n",
    "            # Create a ToolMessage for this result\n",
    "            tool_message = ToolMessage(\n",
    "                content=str(search_results),\n",
    "                tool_call_id=tool_id,\n",
    "                name=tool_name\n",
    "            )\n",
    "            \n",
    "            tool_messages.append(tool_message)\n",
    "    \n",
    "    # Add the tool messages to the state\n",
    "    return {\"messages\": tool_messages}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph():\n",
    "    # Initialize the graph\n",
    "    graph_builder = StateGraph(State)\n",
    "    \n",
    "    # Add nodes\n",
    "    graph_builder.add_node(\"supervisor\", supervisor)\n",
    "    graph_builder.add_node(\"summary\", summary)\n",
    "    graph_builder.add_node(\"model\", model_node)\n",
    "    graph_builder.add_node(\"open_prompt\",open_prompt)\n",
    "    graph_builder.add_node(\"open_prompt_validator\",open_prompt_validator)\n",
    "    graph_builder.add_node(\"tool_node\", tool_node)\n",
    "\n",
    "    # Set entry point\n",
    "    graph_builder.set_entry_point(\"supervisor\")\n",
    "    \n",
    "    # Add edges\n",
    "    graph_builder.add_edge(\"summary\", END)\n",
    "    \n",
    "    # Conditional edges for tool handling\n",
    "    graph_builder.add_conditional_edges(\"model\", tools_router)\n",
    "    graph_builder.add_edge(\"tool_node\", \"model\")\n",
    "    graph_builder.add_edge(\"open_prompt\",\"open_prompt_validator\")\n",
    "    graph_builder.add_edge(\"open_prompt_validator\", END)\n",
    "\n",
    "    \n",
    "    # Compile the graph\n",
    "    return graph_builder.compile()\n",
    "\n",
    "# Main execution function\n",
    "graph = build_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='What has the both lowest and highest sales', additional_kwargs={}, response_metadata={}, id='aee1c051-20b3-4aa5-ab9c-e9edc9706b86'),\n",
       "  HumanMessage(content='The user is asking for specific data points regarding the lowest and highest sales, which requires querying the data directly rather than summarizing it.', additional_kwargs={}, response_metadata={}, name='supervisor', id='f18371f2-339f-45da-8b8a-a22f219f83e9'),\n",
       "  AIMessage(content='### Summary of Sales Data\\n\\n**Data Overview:**\\n- The dataset contains sales records for two days in January 2023, detailing sales figures by region and product.\\n\\n**Key Insights:**\\n1. **Sales Performance:**\\n   - On January 1, 2023, sales totaled **950** units for **Widget A** in the **South** region.\\n   - On January 2, 2023, sales significantly increased to **1600** units for **Widget B** in the **East** region.\\n\\n2. **Regional Comparison:**\\n   - The **East** region outperformed the **South** region in sales, with a difference of **650** units on January 2.\\n\\n3. **Product Performance:**\\n   - **Widget B** showed a stronger sales performance compared to **Widget A**, indicating a potential preference or demand for this product.\\n\\n4. **Sales Trend:**\\n   - There is a notable increase in sales from January 1 to January 2, suggesting a positive sales trend or effective marketing strategies for Widget B.\\n\\n### Conclusion:\\nThe data indicates varying sales performance across regions and products, with Widget B in the East region showing the highest sales figures. Further analysis could explore factors contributing to these trends.', additional_kwargs={}, response_metadata={}, id='3d0aa9fc-0a01-4ea5-88d6-92e5efb0eb6f')],\n",
       " 'request_type': 'open_prompt',\n",
       " 'formula': \"df[(df['sales'] == df['sales'].min()) | (df['sales'] == df['sales'].max())]\"}"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": 5\n",
    "    }\n",
    "}\n",
    "\n",
    "response = await graph.ainvoke({\n",
    "    \"messages\": [HumanMessage(content=\"What has the both lowest and highest sales\")], \n",
    "})\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": 8\n",
    "    }\n",
    "}\n",
    "\n",
    "# Use async for to iterate over the async generator\n",
    "events=graph.astream_events({\n",
    "    \"messages\": [HumanMessage(content=\"the value\")],\n",
    "}, version=\"v2\")\n",
    "\n",
    "\n",
    "result=\"\"\n",
    "\n",
    "async for event in events: \n",
    "    if event[\"event\"] == \"on_chat_model_stream\":\n",
    "        if (\n",
    "    isinstance(event, dict)\n",
    "    and 'metadata' in event\n",
    "    and isinstance(event['metadata'], dict)\n",
    "    and event['metadata'].get('langgraph_node') not in ('supervisor', 'open_prompt')):\n",
    "\n",
    "            print(event[\"data\"][\"chunk\"].content, end=\"\", flush=True)\n",
    "            result = result + event[\"data\"][\"chunk\"].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Based on the provided data, here is a summary and key insights:\n",
       "\n",
       "### Summary:\n",
       "- **Date of Sale**: January 2, 2023\n",
       "- **Sales Amount**: $1,600\n",
       "- **Region**: East\n",
       "- **Product Sold**: Widget B\n",
       "\n",
       "### Key Insights:\n",
       "1. **Sales Performance**: The sales figure of $1,600 indicates a specific transaction or total sales for the day. This can be used as a benchmark for evaluating sales performance over time.\n",
       "  \n",
       "2. **Regional Focus**: The data is specific to the East region, which may suggest a targeted marketing or sales strategy in that area. Understanding regional performance can help in resource allocation and strategy development.\n",
       "\n",
       "3. **Product Specificity**: The sale of Widget B indicates a focus on this particular product. Analyzing the sales of Widget B over time can provide insights into its popularity and market demand.\n",
       "\n",
       "4. **Temporal Analysis**: Since the data is from the beginning of the year, it can serve as a starting point for tracking sales trends throughout 2023. Comparing this data with future sales data can help identify seasonal trends or the impact of marketing campaigns.\n",
       "\n",
       "5. **Potential for Further Analysis**: While this single data point provides limited insights, aggregating similar data over a longer period or across different regions/products could yield more comprehensive insights into sales trends, customer preferences, and overall business performance.\n",
       "\n",
       "Overall, while the dataset is minimal, it lays the groundwork for deeper analysis and understanding of sales dynamics in the specified region and product category."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown, Latex\n",
    "Markdown(result)\n",
    "# print(event[\"data\"][\"chunk\"].content, end=\"\", flush=True)\n",
    "#             result = result + event[\"data\"][\"chunk\"].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
